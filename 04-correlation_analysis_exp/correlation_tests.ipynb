{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from definitions import *\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_aggregated_data = pd.read_csv(\"./aggregated_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvalues = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rvalues = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pvalue = [[\"test_col\",[]]]\n",
    "data_rvalue = [[\"test_col\",[]]]\n",
    "\n",
    "for col in users_aggregated_data:\n",
    "    data_pvalue.append([col,[]])\n",
    "    data_rvalue.append([col,[]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionando o tipo de teste que sera feito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_correlation = \"spearmanr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation(corr_function =\"pearsonr\"):\n",
    "    for col1 in users_aggregated_data:\n",
    "        data_pvalue[0][1].append(col1)\n",
    "        data_rvalue[0][1].append(col1)\n",
    "        for col2 in users_aggregated_data:\n",
    "            if(corr_function == \"pearsonr\"):\n",
    "                r,p = stats.pearsonr(users_aggregated_data[col1], users_aggregated_data[col2])\n",
    "            if(corr_function == \"spearmanr\"):\n",
    "                r,p = stats.spearmanr(users_aggregated_data[col1], users_aggregated_data[col2])\n",
    "\n",
    "            for i in range(len(data_pvalue)):\n",
    "                if(data_pvalue[i][0] == col2):\n",
    "                    data_pvalue[i][1].append(p)\n",
    "                if(data_rvalue[i][0] == col2):\n",
    "                    data_rvalue[i][1].append(r)\n",
    "\n",
    "calculate_correlation(target_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in data_pvalue:\n",
    "    df_pvalues[dt[0]] = np.array(dt[1])\n",
    "for dt in data_rvalue:\n",
    "    df_rvalues[dt[0]] = np.array(dt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvalues.to_csv(target_correlation+\"/pvalue_tests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rvalues.to_csv(target_correlation+\"/rvalue_tests.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pvalue Filters\n",
    "###### threshold = 0.005 (sobs falou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvalues = pd.read_csv(target_correlation+\"/pvalue_tests.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_p_filters(threshold):\n",
    "    pvalue_threshold = threshold\n",
    "    ref = []\n",
    "    dest = []\n",
    "    val = []\n",
    "    for index, row in df_pvalues.iterrows():\n",
    "        for col in df_pvalues:\n",
    "            if(col!=\"test_col\"):\n",
    "                if(row[col]<=pvalue_threshold):\n",
    "                    if(row[\"test_col\"] in dest and col in ref):\n",
    "                        continue\n",
    "                    ref.append(row[\"test_col\"])\n",
    "                    dest.append(col)\n",
    "                    val.append(row[col])\n",
    "    signif_values_df = pd.DataFrame()\n",
    "    signif_values_df[\"col_a\"] = np.array(ref)\n",
    "    signif_values_df[\"col_b\"] = np.array(dest)\n",
    "    signif_values_df[\"pvalue\"] = np.array(val)\n",
    "    signif_values_df.to_csv(target_correlation+\"/pvalue_filtered/significant_pvalues-\"+str(pvalue_threshold)+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths_values = [0.05,0.01,0.005,0.001,0.0005,0.0001,0.000005,0.000000000000005]\n",
    "for t_val in ths_values:\n",
    "    run_p_filters(t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_map(col):\n",
    "    try:\n",
    "        return int(col.split(\"_\")[1])\n",
    "    except:\n",
    "        return col\n",
    "def map_and_sort_results_p(threshold):\n",
    "    sig_df = pd.read_csv(target_correlation+\"/pvalue_filtered/significant_pvalues-\"+str(threshold)+\".csv\",index_col = 0)\n",
    "    sig_df = sig_df.sort_values(by = ['col_a', 'col_b'], ascending = [True, False], na_position = 'first')\n",
    "    sig_df = sig_df[sig_df[\"col_b\"].str.contains(\"score\")]\n",
    "    sig_df.to_csv(target_correlation+\"/pvalue_filtered/significant_pvalues-\"+str(threshold)+\"-sorted.csv\")\n",
    "    try:\n",
    "        sig_df[\"col_a\"] = sig_df[\"col_a\"].map(col_map)\n",
    "    except:\n",
    "        None\n",
    "    sig_df = sig_df.groupby(['col_a', 'col_b']).count()\n",
    "    sig_df.to_csv(target_correlation+\"/pvalue_filtered/significant_pvalues-\"+str(threshold)+\"-count.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_val in ths_values:\n",
    "    map_and_sort_results_p(t_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rvalue filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rvalues = pd.read_csv(target_correlation+\"/rvalue_tests.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_r_filters(threshold):\n",
    "    rvalue_threshold = threshold\n",
    "    ref = []\n",
    "    dest = []\n",
    "    val = []\n",
    "    for index, row in df_rvalues.iterrows():\n",
    "        for col in df_rvalues:\n",
    "            if(col!=\"test_col\"):\n",
    "                if(row[col]<=-1*rvalue_threshold or row[col]>=rvalue_threshold):\n",
    "                    if(row[\"test_col\"] in dest and col in ref):\n",
    "                        continue\n",
    "                    ref.append(row[\"test_col\"])\n",
    "                    dest.append(col)\n",
    "                    val.append(row[col])\n",
    "    signif_values_df = pd.DataFrame()\n",
    "    signif_values_df[\"col_a\"] = np.array(ref)\n",
    "    signif_values_df[\"col_b\"] = np.array(dest)\n",
    "    signif_values_df[\"rvalue\"] = np.array(val)\n",
    "    signif_values_df.to_csv(target_correlation+\"/rvalue_filtered/significant_rvalues-\"+str(rvalue_threshold)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ths_rvalues = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for t_val in ths_rvalues:\n",
    "    run_r_filters(t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_and_sort_results_r(threshold):\n",
    "    sig_df = pd.read_csv(target_correlation+\"/rvalue_filtered/significant_rvalues-\"+str(threshold)+\".csv\",index_col = 0)\n",
    "    sig_df = sig_df.sort_values(by = ['col_a', 'col_b'], ascending = [True, False], na_position = 'first')\n",
    "    sig_df = sig_df[sig_df[\"col_b\"].str.contains(\"score\")]\n",
    "    sig_df.to_csv(target_correlation+\"/rvalue_filtered/significant_rvalues-\"+str(threshold)+\"-sorted.csv\")\n",
    "    try:\n",
    "        sig_df[\"col_a\"] = sig_df[\"col_a\"].map(col_map)\n",
    "    except:\n",
    "        None\n",
    "    sig_df = sig_df.groupby(['col_a', 'col_b']).count()\n",
    "    sig_df.to_csv(target_correlation+\"/rvalue_filtered/significant_rvalues-\"+str(threshold)+\"-count.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_val in ths_rvalues:\n",
    "    map_and_sort_results_r(t_val)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfeb679b71e72e99b58c3c3eabae007d128c35640555dbe60f185f65b527d03c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('04-correlation_analysis_exp-Wj3_WWyr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
